# Семантический текстовый поиск

Проект для выполнения задачи **семантического текстового поиска** на русском языке с использованием методов семантического анализа текста. Целью является создание системы, которая учитывает не только точное написание, но и смысловое значение слов и фраз в документах. Также реализован веб-интерфейс для ручного тестирования системы.

## Описание

Система выполняет поиск слов или словосочетаний в текстах с оценкой вероятности совпадения. Для поиска используется модель **`SentenceTransformer`**, обученная на русском языке, для преобразования текста в эмбеддинги и вычисления сходства с использованием **`cosine similarity`**. Результаты поиска возвращаются с точностью и вероятностью совпадения.

## Структура проекта

- **`app.py`**: Основной скрипт для Flask-приложения.
- **`model/`**: Папка, содержащая сохранённые модели и эмбеддинги.
- **`data/`**: Папка с исходными данными для обучения модели.
- **`templates/`**: HTML-шаблоны для веб-интерфейса.
- **`requirements.txt`**: Список зависимостей для установки.
- **`Dockerfile`**: Docker конфигурация для контейнеризации приложения.
- **`README.md`**: Документация проекта.

## Требования

Для работы проекта необходимы следующие библиотеки и инструменты:

- Python 3.8 или выше
- Flask
- Sentence-Transformers
- scikit-learn
- pandas
- numpy
- pymorphy2 (для лемматизации)
- nltk (для обработки текста)
- Docker (для контейнеризации)

## Установка

1. Клонируйте репозиторий:
    ```bash
    git clone https://github.com/JarikDev/code_n_conquer.git
    cd code_n_conquer
    ```

2. Установите зависимости:
    ```bash
    pip install -r requirements.txt
    ```

3. (Опционально) Если хотите использовать Docker, создайте и запустите контейнер:
    ```bash
    docker build -t code_n_conquer .
    docker run -p 8081:8081 code_n_conquer
    ```

## Использование

1. Запустите приложение:
    ```bash
    python app.py
    ```

2. Откройте браузер и перейдите по адресу:
    ```
    http://127.0.0.1:8081
    ```

3. Введите текст и фразу для анализа, чтобы получить результат поиска и вероятности совпадения.

4. Для просмотра метрик модели перейдите по адресу:
    ```
    http://127.0.0.1:8081/metrics
    ```

## Функции

- **Семантический поиск**: Применяет модель для поиска фразы в тексте с вычислением вероятности совпадения.
- **Метрики поиска**: Показывает точность, полноту, и другие метрики работы модели.

## Метрики

Метрики качества модели включают:

- **Precision@5**: Точность на топ-5 найденных совпадений.
- **Recall@5**: Полнота на топ-5 найденных совпадений.
- **MRR (Mean Reciprocal Rank)**: Средний обратный ранг.
- **F1-Score**: Оценка точности и полноты для топ-5 совпадений.

## Документация этапов

### 1. Подготовка данных

Для подготовки данных выполнены следующие шаги:

- **Очистка текста**: Приведение всех текстов к нижнему регистру, удаление пунктуации и лишних пробелов.
- **Лемматизация**: Для обработки русского языка использовался лемматизатор **`pymorphy2`**. Это позволяет привести все слова к их базовой форме, улучшая качество поиска.
- **Создание эмбеддингов**: Для текста используется модель **`SentenceTransformer`**, которая генерирует эмбеддинги (векторные представления) для каждого документа.

### 2. Обучение

Модель использует **`SentenceTransformer`**, обученную на русском языке **`ai-forever/sbert_large_nlu_ru`** для создания эмбеддингов. Это позволяет эффективно анализировать семантическое сходство между запросом и документами.

- **Гиперпараметры**:
  - **Модель**: `ai-forever/sbert_large_nlu_ru`
  - **Метод подсчета сходства**: `cosine similarity`
  - **Размерность эмбеддингов**: 768 (по умолчанию для выбранной модели)

### 3. Валидация

Для валидации модели использовались заранее подготовленные запросы и метки "релевантных" документов, чтобы вычислить метрики качества:

- **Precision@5**: Точность поиска среди 5 самых похожих документов.
- **Recall@5**: Полнота поиска среди 5 самых похожих документов.
- **MRR**: Средний обратный ранг для всех запросов.
- **F1-Score**: Оценка баланса между точностью и полнотой.

### 4. Эксплуатация

Для эксплуатации системы был разработан веб-интерфейс на **Flask**. Он позволяет:

- Вводить текст и фразу для поиска.
- Получать результат поиска с вероятностью совпадения.
- Просматривать метрики работы модели.

## Информативность экспериментов

### Используемые данные:

- Для обучения использовались текстовые данные, очищенные от пунктуации и приведенные к нижнему регистру.
- Примеры запросов для валидации включают фразы, такие как "погода на завтра", "новости спорта", и "разговор о здоровье".

### Модели:

- Модель **`SentenceTransformer`** (`ai-forever/sbert_large_nlu_ru`) использовалась для генерации эмбеддингов текста.
  
### Гиперпараметры:

- **Модель**: `ai-forever/sbert_large_nlu_ru`
- **Метод подсчета сходства**: Cosine similarity.
- **Размер эмбеддингов**: 768.
- **Количественный порог для совпадения**: Вероятность совпадения больше 0.6 считается значимым результатом.

### Функции ошибки:

- Для оценки точности модели использовались метрики **Precision@5**, **Recall@5**, **MRR**, и **F1-Score**.
  
## Создание собственного датасета

1. Подготовьте CSV-файл с колонками, содержащими текстовые данные. Убедитесь, что все тексты приведены к нижнему регистру и очищены от пунктуации.
2. Используйте модель **`SentenceTransformer`** для создания эмбеддингов и обучения модели.

## Тестирование

Для тестирования можно использовать **pytest**:

```bash
pip install pytest
pytest
